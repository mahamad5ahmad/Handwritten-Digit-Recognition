{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 13s 1us/step\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 41s 691us/step - loss: 0.3833 - accuracy: 0.8774 - val_loss: 0.0963 - val_accuracy: 0.9713\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 39s 653us/step - loss: 0.0967 - accuracy: 0.9704 - val_loss: 0.0463 - val_accuracy: 0.9844\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 38s 629us/step - loss: 0.0715 - accuracy: 0.9777 - val_loss: 0.0380 - val_accuracy: 0.9876\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 38s 631us/step - loss: 0.0573 - accuracy: 0.9822 - val_loss: 0.0302 - val_accuracy: 0.9899\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 38s 627us/step - loss: 0.0486 - accuracy: 0.9847 - val_loss: 0.0292 - val_accuracy: 0.9900\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 38s 637us/step - loss: 0.0423 - accuracy: 0.9870 - val_loss: 0.0280 - val_accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 39s 642us/step - loss: 0.0386 - accuracy: 0.9877 - val_loss: 0.0292 - val_accuracy: 0.9907\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 38s 636us/step - loss: 0.0340 - accuracy: 0.9889 - val_loss: 0.0258 - val_accuracy: 0.9910\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 38s 638us/step - loss: 0.0316 - accuracy: 0.9901 - val_loss: 0.0237 - val_accuracy: 0.9926\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 38s 639us/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 0.0268 - val_accuracy: 0.9907\n",
      "Large CNN Error: 0.93%\n"
     ]
    }
   ],
   "source": [
    "# Larger CNN for the MNIST Dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][width][height][channels]\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define the larger model\n",
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D())\n",
    "\tmodel.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D())\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# build the model\n",
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
